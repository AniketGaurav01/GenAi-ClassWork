{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UuvZlJAjUaCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308ac703-4c1c-414c-85f3-6be2831ebf8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, metrics, backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "metadata": {
        "id": "pMh86valVc3C"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(28, 28, 1), name=\"encoder_input\")\n",
        "x = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n",
        "x = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(2, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(2, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")"
      ],
      "metadata": {
        "id": "m1to8uJjVc5l"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
        "x = layers.Dense(14*14*128)(decoder_input)\n",
        "x = layers.Reshape((14, 14, 128))(x)\n",
        "x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding=\"same\")(x)\n",
        "decoder = models.Model(decoder_input, x)"
      ],
      "metadata": {
        "id": "Vzt1GgAoVdAj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z_mean, z_log_var, reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, reconstruction = self(data)\n",
        "            reconstruction_loss = 500 * tf.reduce_mean(\n",
        "                binary_crossentropy(data, reconstruction))\n",
        "            kl_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1)\n",
        "            )\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "tGCwjH8eVdDh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the VAE model\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=\"adam\")\n",
        "vae.fit(\n",
        "    x_train,\n",
        "    epochs=3,\n",
        "    batch_size=100\n",
        ")"
      ],
      "metadata": {
        "id": "Dgk4XMBfUaEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a48be4-8f55-42fa-9faf-af0c621ca58a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 307ms/step - kl_loss: 0.4402 - reconstruction_loss: 0.4693 - total_loss: 0.5134\n",
            "Epoch 2/3\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 296ms/step - kl_loss: 0.0996 - reconstruction_loss: 0.4804 - total_loss: 0.4903\n",
            "Epoch 3/3\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 292ms/step - kl_loss: 0.0908 - reconstruction_loss: 0.4813 - total_loss: 0.4904\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7beb8e2dc0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: reduce the KL loss and overall total loss\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z_mean, z_log_var, reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, reconstruction = self(data)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                binary_crossentropy(data, reconstruction)\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + 0.1 * kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# ... (rest of the code)\n"
      ],
      "metadata": {
        "id": "gGQzr2rsc3g5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#updated part"
      ],
      "metadata": {
        "id": "zSRR35eNaNde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import DepthwiseConv2D, Conv2D\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(28, 28, 1), name=\"encoder_input\")\n",
        "x = DepthwiseConv2D((3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n",
        "x = Conv2D(32, (1, 1), activation=\"relu\")(x)\n",
        "x = DepthwiseConv2D((3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = Conv2D(64, (1, 1), activation=\"relu\")(x)\n",
        "x = DepthwiseConv2D((3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = Conv2D(128, (1, 1), activation=\"relu\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(2, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(2, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
        "x = layers.Dense(14*14*128)(decoder_input)\n",
        "x = layers.Reshape((14, 14, 128))(x)\n",
        "x = DepthwiseConv2D((3, 3), strides=1, activation='relu', padding=\"same\")(x)\n",
        "x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding=\"same\")(x)\n",
        "decoder = models.Model(decoder_input, x)\n"
      ],
      "metadata": {
        "id": "SsHbDmEEaNfm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdBFta1KaNh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkN3wj8VaNj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4FjUDUxaNmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28jKwWQ7aNoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-8yHEJ9aNqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJQshKIZaNtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}